{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import random\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "env = gym.envs.make(\"PongDeterministic-v4\")\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "\n",
    "#try:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_action = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import copy\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, n_channel, n_action):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=n_channel, out_channels=32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, stride=1)\n",
    "        self.fc = torch.nn.Linear(22 * 16 * 32, 512)\n",
    "        self.out = torch.nn.Linear(512, n_action)\n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.conv2(x))\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.conv3(x))\n",
    "#         print(x.shape)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.fc(x))\n",
    "#         print(x.shape)\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, n_channel, n_action):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=n_channel, out_channels=32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, stride=1)\n",
    "        self.fc = torch.nn.Linear(7 * 7 * 64, 512)\n",
    "        self.out = torch.nn.Linear(512, n_action)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc(x))\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN():\n",
    "    def __init__(self, n_channel, n_action, lr=0.05):\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        self.model = CNNModel(n_channel, n_action)\n",
    "        self.model.to(device)\n",
    "        self.model_target = copy.deepcopy(self.model)\n",
    "        self.model.share_memory()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr)\n",
    "        print(self.model)\n",
    "#         for n. p in self.model.named_parametrs():\n",
    "#             print(n,p.device)\n",
    "    def update(self, s, y):\n",
    "        \"\"\"\n",
    "        Update the weights of the DQN given a training sample\n",
    "        @param s: state\n",
    "        @param y: target value\n",
    "        \"\"\"\n",
    "        #print(\"y_pred loss\",np.array(s).shape, np.array(y).shape)\n",
    "        y_pred = self.model(torch.tensor(s, dtype = torch.float32).to(device))\n",
    "        loss = self.criterion(y_pred, torch.tensor(y, dtype = torch.float32).to(device))\n",
    "       \n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "    def predict(self, s):\n",
    "        \"\"\"\n",
    "        Compute the Q values of the state for all actions using the learning model\n",
    "        @param s: input state\n",
    "        @return: Q values of the state for all actions\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            return self.model(torch.Tensor(s, dtype = torch.float32))#.to(device))\n",
    "    def target_predict(self, s):\n",
    "        \"\"\"\n",
    "        Compute the Q values of the state for all actions using the target network\n",
    "        @param s: input state\n",
    "        @return: targeted Q values of the state for all actions\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            return self.model_target(torch.Tensor(s, dtype = torch.float32).to(device))#.to(device))\n",
    "\n",
    "    def replay(self, memory, replay_size, gamma):\n",
    "        \"\"\"\n",
    "        Experience replay with target network\n",
    "        @param memory: a list of experience\n",
    "        @param replay_size: the number of samples we use to update the model each time\n",
    "        @param gamma: the discount factor\n",
    "        \"\"\"\n",
    "        if len(memory) >= replay_size:\n",
    "            replay_data = random.sample(memory, replay_size)\n",
    "            states = []\n",
    "            td_targets = []\n",
    "            for state, action, next_state, reward, is_done in replay_data:\n",
    "                states.append(state.tolist()[0])\n",
    "                q_values = self.predict(state).tolist()[0]\n",
    "                if is_done:\n",
    "                    q_values[action] = reward\n",
    "                else:\n",
    "                    q_values_next = self.target_predict(next_state).detach()\n",
    "\n",
    "                    q_values[action] = reward + gamma * torch.max(q_values_next).item()\n",
    "\n",
    "                td_targets.append(q_values)\n",
    "\n",
    "            self.update(states, td_targets)\n",
    "\n",
    "    def copy_target(self):\n",
    "        self.model_target.load_state_dict(self.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN():\n",
    "    def __init__(self, n_channel, n_action, lr=0.05):\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        self.model = CNNModel(n_channel, n_action)\n",
    "        self.model.to(device)\n",
    "       # self.model_target = copy.deepcopy(self.model)\n",
    "        self.model_target = CNNModel(n_channel, n_action)\n",
    "        self.model_target.to(device)   \n",
    "        self.model.share_memory()\n",
    "        self.model_target.load_state_dict(self.model.state_dict()) \n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr)\n",
    "        print(self.model)\n",
    "        print(\"trainable_params\",sum(p.numel() for p in self.model.parameters() if p.requires_grad))\n",
    "\n",
    "    def update(self, s, y):\n",
    "        \"\"\"\n",
    "        Update the weights of the DQN given a training sample\n",
    "        @param s: state\n",
    "        @param y: target value\n",
    "        \"\"\"\n",
    "        #print(\"y_pred loss\",np.array(s).shape, np.array(y).shape)\n",
    "        y_pred = self.model(torch.tensor(s, dtype = torch.float32).to(device))\n",
    "        loss = self.criterion(y_pred, torch.tensor(y, dtype = torch.float32).to(device))\n",
    "       \n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "    def predict(self, s):\n",
    "        \"\"\"\n",
    "        Compute the Q values of the state for all actions using the learning model\n",
    "        @param s: input state\n",
    "        @return: Q values of the state for all actions\n",
    "        \"\"\"\n",
    "       # with torch.no_grad():\n",
    "        self.model.share_memory()\n",
    "        return self.model(torch.tensor(s, dtype = torch.float32).to(device))#)\n",
    "    def target_predict(self, s):\n",
    "        \"\"\"\n",
    "        Compute the Q values of the state for all actions using the target network\n",
    "        @param s: input state\n",
    "        @return: targeted Q values of the state for all actions\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            return self.model_target(torch.tensor(s, dtype = torch.float32).to(device))#.to(device))\n",
    "\n",
    "    def replay(self, memory, replay_size, gamma):\n",
    "        \"\"\"\n",
    "        Experience replay with target network\n",
    "        @param memory: a list of experience\n",
    "        @param replay_size: the number of samples we use to update the model each time\n",
    "        @param gamma: the discount factor\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(memory) >= replay_size:\n",
    "            s1 = time.perf_counter()\n",
    "            replay_data = random.sample(memory, replay_size)\n",
    "            s2 = time.perf_counter()\n",
    "           # time1.append(s2-s1)\n",
    "            #states = []\n",
    "            states = np.zeros((replay_size,3, 84, 84),dtype = \"float32\")\n",
    "            td_targets = []\n",
    "            i = 0\n",
    "            for state, action, next_state, reward, is_done in replay_data:\n",
    "                \n",
    "              #  print(state, state.shape, type(state))\n",
    "                s1 = time.perf_counter()\n",
    "                states[i]= state.numpy()[0]\n",
    "#                 states.append(state.tolist()[0])\n",
    "                s2 = time.perf_counter()\n",
    "                time2.append(s2-s1)   #!!!\n",
    "                s1 = time.perf_counter()\n",
    "                q_values = self.predict(state).tolist()[0]\n",
    "                #print(q_values)\n",
    "                s2 = time.perf_counter()\n",
    "               # time3.append(s2-s1)   #!!!\n",
    "                if is_done:\n",
    "                    q_values[action] = reward\n",
    "                else:\n",
    "                    s1 = time.perf_counter()\n",
    "                    q_values_next = self.target_predict(next_state).detach()\n",
    "                   # print(111, self.target_predict(next_state))\n",
    "                    s2 = time.perf_counter()\n",
    "                  #  time4.append(s2-s1)    #!!!\n",
    "                    s1 = time.perf_counter()\n",
    "                    q_values[action] = reward + gamma * torch.max(q_values_next).item()\n",
    "                    s2 = time.perf_counter()\n",
    "                  #  time5.append(s2-s1)\n",
    "                td_targets.append(q_values)\n",
    "                i+=1\n",
    "            s1 = time.perf_counter()\n",
    "            self.update(states, td_targets)\n",
    "            s2 = time.perf_counter()\n",
    "           # time6.append(s2-s1)\n",
    "#         print(\"time1\",np.mean(np.array(time1)),np.sum(np.array(time1)), len(time1))\n",
    "#             print(\"time2\",np.mean(np.array(time2)), np.sum(np.array(time2)),len(time2))\n",
    "#         print(\"time3\",np.mean(np.array(time3)),np.sum(np.array(time3)), len(time3))\n",
    "#         print(\"time4\",np.mean(np.array(time4)), np.sum(np.array(time4)),len(time4))\n",
    "#         print(\"time5\",np.mean(np.array(time5)),np.sum(np.array(time5)), len(time5))\n",
    "#         print(\"time6\",np.mean(np.array(time6)), np.sum(np.array(time6)),len(time6))\n",
    "\n",
    "    def copy_target(self):\n",
    "        self.model_target.load_state_dict(self.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = CNNModel(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNModel(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc): Linear(in_features=3136, out_features=512, bias=True)\n",
      "  (out): Linear(in_features=512, out_features=3, bias=True)\n",
      ")\n",
      "trainable_params 1683619\n"
     ]
    }
   ],
   "source": [
    "n_episode = 1000\n",
    "lr = 0.00025\n",
    "replay_size = 32\n",
    "target_update = 10\n",
    "dqn = DQN(3, n_action, lr)\n",
    "memory = deque(maxlen=100000)\n",
    "total_reward_episode = [0] * n_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683619"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in torch_model.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(np.random.rand(32, 3, 84, 84),dtype = torch.float32)#.shape\n",
    "y = torch.tensor(np.random.rand(32, 3),dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.random.rand(3).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(1, 3, 84, 84).astype(\"float32\")#.shape\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import torch.multiprocessing as mp\n",
    "\n",
    "\n",
    "# def train(model):\n",
    "#     # Construct data_loader, optimizer, etc.\n",
    "#     for data, labels in (x, y):\n",
    "#         optimizer.zero_grad()\n",
    "#         loss_fn(model(data), labels).backward()\n",
    "#         optimizer.step()  # This will update the shared parameters\n",
    "\n",
    "# #if __name__ == '__main__':\n",
    "# num_processes = 1\n",
    "# model = CNNModel(3, 3).to(device)\n",
    "# # NOTE: this is required for the ``fork`` method to work\n",
    "# #model.share_memory()\n",
    "# processes = []\n",
    "# for rank in range(num_processes):\n",
    "#     #sleep(2)\n",
    "#     p = mp.Process(target=train, args=(model,))\n",
    "#     p.start()\n",
    "#     processes.append(p)\n",
    "# for p in processes:\n",
    "#     p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.6 ms, sys: 0 ns, total: 39.6 ms\n",
      "Wall time: 4.95 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aa = dqn.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 ms, sys: 9.81 ms, total: 25.4 ms\n",
      "Wall time: 2.09 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aa = dqn.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811 µs ± 14.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit    dqn.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = time.perf_counter()\n",
    "kk = dqn.predict(x)\n",
    "s2 = time.perf_counter()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001771 /n\n"
     ]
    }
   ],
   "source": [
    "print(round(s2-s1, 6),\"/n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.multiprocessing import Pool, Process, set_start_method\n",
    "# #try:\n",
    "# set_start_method('spawn')\n",
    "# #except RuntimeError:\n",
    "#    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# def f(x):\n",
    "#     time.sleep(3)\n",
    "#     return x*x\n",
    "\n",
    "\n",
    "# with Pool(5) as p:\n",
    "#     print(p.map(f, [1, 2, 3]))\n",
    "#     print(p.map(f, [1, 2, 3]))\n",
    "#     print(p.map(f, [1, 2, 3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 84, 84)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.multiprocessing import Pool, Process, set_start_method\n",
    "#set_start_method('spawn')\n",
    "#orch.multiprocessing.get_all_sharing_strategies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = CNNModel(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc): Linear(in_features=3136, out_features=512, bias=True)\n",
       "  (out): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0319,  0.0105, -0.0247]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model(torch.tensor(x, dtype = torch.float32).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "listx = []\n",
    "for i in range(32):\n",
    "    listx.append(torch.tensor(x, dtype = torch.float32) )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MaybeEncodingError",
     "evalue": "Error sending result: '[tensor([[ 0.0319,  0.0105, -0.0247]], grad_fn=<AddmmBackward>), tensor([[ 0.0319,  0.0105, -0.0247]], grad_fn=<AddmmBackward>), tensor([[ 0.0319,  0.0105, -0.0247]], grad_fn=<AddmmBackward>)]'. Reason: 'RuntimeError('Cowardly refusing to serialize non-leaf tensor which requires_grad, since autograd does not support crossing process boundaries.  If you just want to transfer the data, call detach() on the tensor before serializing (e.g., putting it on the queue).')'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaybeEncodingError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-b140983eb11b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaybeEncodingError\u001b[0m: Error sending result: '[tensor([[ 0.0319,  0.0105, -0.0247]], grad_fn=<AddmmBackward>), tensor([[ 0.0319,  0.0105, -0.0247]], grad_fn=<AddmmBackward>), tensor([[ 0.0319,  0.0105, -0.0247]], grad_fn=<AddmmBackward>)]'. Reason: 'RuntimeError('Cowardly refusing to serialize non-leaf tensor which requires_grad, since autograd does not support crossing process boundaries.  If you just want to transfer the data, call detach() on the tensor before serializing (e.g., putting it on the queue).')'"
     ]
    }
   ],
   "source": [
    "#from multiprocessing import Pool\n",
    "if __name__ == '__main__':\n",
    "    with Pool(3) as p:\n",
    "        p.map(torch_model, listx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(x):\n",
    "    torch_model()\n",
    "#     s1 = time.perf_counter()\n",
    "#     kk = dqn.predict(x)\n",
    "#     s2 = time.perf_counter()\n",
    "#     print(round(s2-s1, 5),\"/n\")\n",
    "    return round(s2-s1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d376916f0a5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-e21fb78ae3ae>\u001b[0m in \u001b[0;36mpredict_test\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtorch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#     s1 = time.perf_counter()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     kk = dqn.predict(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     s2 = time.perf_counter()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "predict_test(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "listx = []\n",
    "for i in range(32):\n",
    "    listx.append(np.random.rand(1, 3, 84, 84).astype(\"float32\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures as pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executer = pool.ProcessPoolExecutor(max_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executerlist = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name in listx:\n",
    "    executerlist.append(executer.submit(predict_test,\n",
    "                                        x = name,\n",
    "#                                         yy = yy,\n",
    "#                                         zz = zz,\n",
    "                                        ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = pool.wait(executerlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summ = 0 \n",
    "for future in ok.done:\n",
    "    result = future.result()\n",
    "    summ += result\n",
    "   # print(result)\n",
    "print(1111,summ)\n",
    "del executerlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1111 0.051899999999999995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    executer.shutdown()\n",
    "except: pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x)\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit x.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k = []\n",
    "k = np.zeros((32,3, 84, 84),dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range (32):\n",
    "    k[i]= (x.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit torch.tensor(k, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(100):\n",
    "    k.append(x.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit k.append((x.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit k.append(x.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit  k.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit k.append(x.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(10000):\n",
    "    kk = x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#dqn.update(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "    dqn.update(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda\n",
    "first\n",
    "Wall time: 419 ms\n",
    "    \n",
    "cpu\n",
    "Wall time: 210 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda\n",
    "second\n",
    "Wall time: 64.4 ms\n",
    "cpu    \n",
    "Wall time: 162 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda\n",
    "first\n",
    "Wall time: 980 ms\n",
    "    \n",
    "cpu\n",
    "Wall time: 3.51 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda\n",
    "second\n",
    "Wall time: 627 ms\n",
    "cpu    \n",
    "Wall time: 3.27 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second 2048\n",
    "keras      torch\n",
    "    cpu:\n",
    "3.31 s     3.27 s  \n",
    "    cuda:\n",
    "880 ms    627 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras = keras.models.Sequential()\n",
    "model_keras.add(keras.layers.Conv2D(32, (8,8), input_shape=( 210, 160, 3), strides=(4, 4)))\n",
    "model_keras.add(keras.layers.ReLU())\n",
    "# model_keras.add(keras.layers.BatchNormalization())\n",
    "model_keras.add(keras.layers.Conv2D(32, (4,4),strides=(2, 2)))\n",
    "model_keras.add(keras.layers.ReLU())\n",
    "# model_keras.add(keras.layers.BatchNormalization())\n",
    "model_keras.add(keras.layers.Conv2D(32, 3, 1))\n",
    "model_keras.add(keras.layers.ReLU())\n",
    "# model_keras.add(keras.layers.ELU())\n",
    "# model_keras.add(keras.layers.BatchNormalization())\n",
    "# model_keras.add(keras.layers.MaxPool2D(pool_size=(2, 2), strides= (2,2)))\n",
    "model_keras.add(keras.layers.Flatten())\n",
    "model_keras.add(keras.layers.Dense(512))\n",
    "model_keras.add(keras.layers.ReLU())\n",
    "model_keras.add(keras.layers.Dense(3))\n",
    "model_keras.add(keras.layers.ReLU())\n",
    "model_keras.compile(loss='mse', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(32,  210, 160, 3)#.shape\n",
    "y = np.random.rand(32, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model_keras.fit(x,y, epochs = 10, batch_size = 32, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu\n",
    "# first \n",
    "# Wall time: 580 ms\n",
    "# second\n",
    "# Wall time: 166 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda\n",
    "# first \n",
    "#Wall time: 17.1 s\n",
    "#second   \n",
    "#Wall time: 93 ms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu\n",
    "# first \n",
    "# Wall time: 3.96 s\n",
    "# second\n",
    "# Wall time: 3.31 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda\n",
    "# first \n",
    "#Wall time: 5.26 s\n",
    "\n",
    "#second   \n",
    "#WWall time: 880 ms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda\n",
    "torch:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
